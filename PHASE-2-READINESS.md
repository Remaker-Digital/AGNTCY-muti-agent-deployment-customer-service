# Phase 2: Business Logic Implementation - Readiness Summary

**Status**: Ready to begin
**Phase**: 2 of 5
**Budget**: $0/month (local development)
**Duration Estimate**: 6-8 weeks
**Milestone Due Date**: 2026-04-30

---

## üìã Phase 2 Overview

### Objective
Implement the business logic of the multi-agent customer service system using AGNTCY SDK patterns, with full integration to mock APIs and comprehensive agent intelligence.

### Current Status: Phase 1 Assessment

**Phase 1 Completion Status** (from CLAUDE.md):
- ‚úÖ 95% Complete
- ‚úÖ Docker Compose with 13 services running
- ‚úÖ All 4 mock APIs implemented (Shopify, Zendesk, Mailchimp, Google Analytics)
- ‚úÖ All 5 agents implemented with AGNTCY SDK integration
- ‚úÖ Shared utilities complete (factory, models, utils)
- ‚úÖ Test framework complete (63 tests passing, 46% coverage)
- ‚è≥ GitHub Actions CI workflow (remaining)

**Transition Readiness**: ‚úÖ Ready to move to Phase 2
- All infrastructure is in place
- Mock services operational
- Agent skeletons functional
- Test framework established

---

## üéØ Phase 2 Goals

### Primary Deliverables

1. **Agent Intelligence Implementation** (5 agents)
   - Intent Classification Agent: Full routing logic
   - Knowledge Retrieval Agent: Search and context building
   - Response Generation Agent: Natural language responses
   - Escalation Agent: Decision-making logic
   - Analytics Agent: Metrics collection and analysis

2. **Conversation Flow Management**
   - Multi-turn conversation handling
   - Context preservation across messages
   - Session management with AppSession
   - Error handling and fallback responses

3. **Integration with Mock Services**
   - Shopify: Orders, products, customers, inventory
   - Zendesk: Ticket creation, updates, webhooks
   - Mailchimp: Subscriber management, campaigns
   - Google Analytics: Event tracking (mocked)

4. **AGNTCY SDK Integration**
   - A2A protocol for agent communication
   - Topic-based message routing
   - Message format with contextId/taskId
   - Factory pattern usage (singleton)

5. **Testing & Quality**
   - Integration tests against mock services
   - Conversation flow testing
   - Agent communication testing
   - Increase test coverage from 46% to >70%

---

## üìä Work Breakdown: 50 User Stories

### By Actor Distribution

| Actor | Stories | Issue Numbers | Priority |
|-------|---------|---------------|----------|
| **Customer** | 30 | #24-#53 | High |
| **Prospect** | 10 | #54-#63 | Medium |
| **Support** | 5 | #64-#68 | High |
| **Service** | 2 | #69-#70 | Medium |
| **Sales** | 2 | #71-#72 | Medium |
| **AI Assistant** | 1 | #73 | Medium |
| **TOTAL** | **50** | **#24-#73** | - |

### By Component/Theme

**Customer Stories (30)** - Issues #24-#53
- Order management (status, tracking, modifications, cancellations)
- Product inquiries (recommendations, comparisons, inventory)
- Returns & refunds
- Subscriptions & loyalty programs
- Shipping & delivery
- Payment issues
- Account management

**Prospect Stories (10)** - Issues #54-#63
- Product discovery
- Information gathering (ingredients, pricing, policies)
- Email list signup
- Lead capture
- First-time buyer incentives

**Support/Service/Sales (10)** - Issues #64-#73
- Ticket workflow integration
- Context preservation
- Escalation management
- Knowledge base updates
- High-value lead handling
- Cart recovery

### Story Complexity Estimation

| Complexity | Count | Story Points | Examples |
|------------|-------|--------------|----------|
| **Simple** | 15 | 1-2 | Product info lookup, email capture |
| **Medium** | 25 | 3-5 | Order status with tracking, returns policy |
| **Complex** | 10 | 8-13 | Multi-turn conversations, escalation logic |
| **TOTAL** | **50** | **~200** | - |

---

## üõ†Ô∏è Technical Work Required

### 1. Agent Implementation (5 agents)

#### Intent Classification Agent
**Location**: `agents/intent_classification/`
**Work Required**:
- [ ] Implement intent detection logic
  - Order status queries
  - Product inquiries
  - Returns/refunds
  - Account issues
  - Service requests
  - Sales opportunities
- [ ] Multi-language intent detection (Phase 4 prep)
- [ ] Confidence scoring
- [ ] Fallback handling for unknown intents
- [ ] Route messages to appropriate agents via A2A protocol

**Key Files**:
- `agents/intent_classification/agent.py`
- `agents/intent_classification/intents.py`
- `agents/intent_classification/router.py`

**Dependencies**:
- AGNTCY SDK A2A protocol
- Message models from `shared/models.py`
- Factory from `shared/factory.py`

#### Knowledge Retrieval Agent
**Location**: `agents/knowledge_retrieval/`
**Work Required**:
- [ ] Implement search across mock APIs
  - Shopify product catalog
  - Order history
  - Customer data
- [ ] Knowledge base integration (mock)
  - Return policies
  - Shipping information
  - Product details
- [ ] Context building from search results
- [ ] Relevance ranking
- [ ] Result formatting for Response Generator

**Key Files**:
- `agents/knowledge_retrieval/agent.py`
- `agents/knowledge_retrieval/search.py`
- `agents/knowledge_retrieval/knowledge_base.py`

**Dependencies**:
- Mock Shopify API (port 8001)
- Mock knowledge base data
- Context models

#### Response Generation Agent
**Location**: `agents/response_generation/`
**Work Required**:
- [ ] Natural language response templates
  - Order status responses
  - Product information
  - Policy explanations
  - Error messages
  - Confirmation messages
- [ ] Context-aware response generation
- [ ] Tone and style consistency
- [ ] Personalization (customer name, order details)
- [ ] Response validation
- [ ] Fallback responses

**Key Files**:
- `agents/response_generation/agent.py`
- `agents/response_generation/templates.py`
- `agents/response_generation/formatter.py`

**Dependencies**:
- Context from Knowledge Retrieval
- Customer data from mock Shopify
- Template engine (Jinja2 or similar)

#### Escalation Agent
**Location**: `agents/escalation/`
**Work Required**:
- [ ] Escalation criteria detection
  - Delivery issues (missing packages)
  - Product quality complaints
  - Refund requests outside policy
  - Complex inquiries beyond AI capability
  - Customer frustration/sentiment
- [ ] Priority assignment logic
  - Critical: Missing deliveries, payment issues
  - High: Product defects, urgent requests
  - Medium: General support needs
  - Low: Information requests
- [ ] Queue routing
  - Support queue (general customer service)
  - Service queue (repairs, warranties)
  - Sales queue (bulk orders, high-value)
- [ ] Zendesk ticket creation
- [ ] Context packaging for human agents

**Key Files**:
- `agents/escalation/agent.py`
- `agents/escalation/criteria.py`
- `agents/escalation/ticket_creator.py`

**Dependencies**:
- Mock Zendesk API (port 8002)
- Conversation history
- Sentiment analysis (basic)

#### Analytics Agent
**Location**: `agents/analytics/`
**Work Required**:
- [ ] Metrics collection
  - Conversation counts
  - Intent distribution
  - Escalation rates
  - Response times
  - Customer satisfaction indicators
- [ ] Event logging
- [ ] Performance tracking
- [ ] KPI calculation
  - Automation rate (target: 70%+)
  - Response time (target: <2min)
  - Escalation accuracy
- [ ] Mock Google Analytics integration

**Key Files**:
- `agents/analytics/agent.py`
- `agents/analytics/metrics.py`
- `agents/analytics/events.py`

**Dependencies**:
- Mock Google Analytics API (port 8004)
- Conversation logs
- Performance data

### 2. Conversation Flow Management

**Location**: `shared/conversation.py`
**Work Required**:
- [ ] Session management using AGNTCY AppSession
  - Create sessions per conversation
  - Store context across messages
  - Timeout handling (configurable)
  - Session cleanup
- [ ] Multi-turn conversation handling
  - Context preservation
  - Follow-up question detection
  - Clarification requests
  - Conversation threading via contextId
- [ ] Error handling
  - API failures (mock service down)
  - Invalid inputs
  - Timeout scenarios
  - Graceful degradation

**Key Files**:
- `shared/conversation.py`
- `shared/session_manager.py`
- `shared/context.py`

### 3. Mock API Integration

**Work Required**:
- [ ] Enhance mock Shopify API
  - Add realistic test scenarios
  - Edge cases (out of stock, discontinued products)
  - Order states (pending, shipped, delivered, cancelled)
  - Customer types (new, returning, VIP)
- [ ] Enhance mock Zendesk API
  - Ticket lifecycle
  - Queue management
  - Comment threads
  - Status updates
- [ ] Enhance mock Mailchimp API
  - Subscriber states
  - List management
  - Tag operations
  - Campaign tracking (mock)
- [ ] Add test data diversity
  - Multiple customer profiles
  - Various order scenarios
  - Different product types

**Key Files**:
- `mocks/shopify/api.py`
- `mocks/zendesk/api.py`
- `mocks/mailchimp/api.py`
- `test-data/shopify/*.json`
- `test-data/zendesk/*.json`
- `test-data/mailchimp/*.json`

### 4. Testing Infrastructure

**Work Required**:
- [ ] Integration test suite
  - Agent-to-agent communication
  - End-to-end conversation flows
  - Mock API integration
  - Error scenarios
- [ ] Conversation flow tests
  - Single-turn conversations
  - Multi-turn conversations
  - Context preservation
  - Intent switching
- [ ] Performance tests (local)
  - Response time benchmarks
  - Concurrent conversation handling
  - Memory usage
- [ ] Increase test coverage
  - From 46% to >70%
  - Focus on agent logic
  - Mock integration coverage

**Key Files**:
- `tests/integration/test_agents.py`
- `tests/integration/test_conversations.py`
- `tests/integration/test_mock_apis.py`

---

## üì¶ Dependencies & Prerequisites

### Software Requirements
- ‚úÖ Python 3.12+ (already installed)
- ‚úÖ Docker Desktop for Windows (already running)
- ‚úÖ AGNTCY SDK installed via pip (already installed)
- ‚úÖ All mock APIs operational (Phase 1 complete)

### AGNTCY SDK Components Needed
- ‚úÖ AgntcyFactory (singleton pattern)
- ‚úÖ A2A protocol for agent communication
- ‚úÖ SLIM transport (secure, low-latency)
- ‚úÖ AppSession for session management
- ‚úÖ Message format (contextId, taskId)

### New Python Packages (if needed)
```bash
# Add to requirements.txt if not present
jinja2>=3.1.0          # Response templating
pytest-asyncio>=0.21.0 # Async testing
faker>=18.0.0          # Test data generation
```

---

## üéØ Required Input/Actions from You

### 1. Business Logic Decisions

#### Response Style & Tone
**Decision Needed**: Define the voice and tone for AI responses
- [ ] Formal vs. conversational?
- [ ] Use customer's name in responses?
- [ ] Emoji usage (if any)?
- [ ] Length preference (concise vs detailed)?

**Example Response Styles**:

**Option A - Concise & Professional**:
```
Your order #10234 shipped yesterday via USPS.
Tracking: 9400123456789
Expected delivery: Jan 25
Track here: [link]
```

**Option B - Conversational & Friendly**:
```
Great news! Your order #10234 is on its way! üì¶

It shipped yesterday with USPS and should arrive by Jan 25.
Your tracking number is 9400123456789.

Need anything else? I'm here to help!
```

**Option C - Detailed & Helpful**:
```
I've checked your order #10234 and have good news!

Status: In Transit
Shipped: Jan 20 via USPS Priority Mail
Tracking: 9400123456789
Expected Delivery: Jan 25 by 8pm

You can track your package here: [link]

If you don't receive it by Jan 26, please let me know and I'll look into it for you.
```

**Your Choice**: _________________

#### Escalation Thresholds
**Decision Needed**: When should AI escalate to human agents?

**Always Escalate**:
- [ ] Missing/stolen deliveries? (Yes/No)
- [ ] Refund requests? (Yes/No/Only if >$X)
- [ ] Product defects? (Yes/No/Only if within X days)
- [ ] Frustrated customers? (Yes/No/After X messages)

**Your Thresholds**:
- Missing delivery escalation: ___________
- Refund auto-approval limit: $___________
- Product defect return window: ________ days
- Frustration detection: After ________ unclear responses

#### Automation Goals
**Decision Needed**: What percentage of queries should AI handle end-to-end?

From PROJECT-README.txt: Target is 70%+ automation rate

**Which query types should be fully automated?**
- [ ] Order status inquiries (Yes/No)
- [ ] Product information (ingredients, pricing) (Yes/No)
- [ ] Shipping policy questions (Yes/No)
- [ ] Return policy questions (Yes/No)
- [ ] Simple refund requests <$X (Yes/No, what threshold?)
- [ ] Out-of-stock notifications (Yes/No)
- [ ] Email list signup (Yes/No)

### 2. Test Data & Scenarios

**Decision Needed**: Provide realistic test scenarios

**Customer Profiles Needed**:
Please provide 3-5 realistic customer personas:
1. **Customer Type**: (e.g., "Frequent buyer, loyalist, prefers lavender products")
   - Name: ___________
   - Purchase history: ___________
   - Preferred products: ___________
   - Typical inquiries: ___________

2. **Customer Type**: (e.g., "First-time buyer, price-sensitive, asks lots of questions")
   - Name: ___________
   - Behavior: ___________
   - Needs: ___________

(Provide as many as you'd like)

**Common Scenarios**:
What are the top 10 most common customer service scenarios you handle?
1. ___________
2. ___________
3. ___________
(Continue as needed)

### 3. Knowledge Base Content

**Decision Needed**: Provide key policies and information

**Required Content**:
- [ ] Return/refund policy (full text)
- [ ] Shipping policy (delivery times, carriers, costs)
- [ ] Product warranty/guarantee information
- [ ] Bulk order pricing (if applicable)
- [ ] Loyalty program details (if applicable)
- [ ] Gift wrapping/messaging options

**Format**: Can be provided as:
- Text documents
- Current website URLs to scrape
- Existing documentation files

### 4. Priority Guidance

**Decision Needed**: Which stories to implement first?

Looking at the 50 Phase 2 stories, which are most critical for your business?

**Suggested Priority Order** (you can modify):
1. **Critical** - Must have for MVP:
   - Customer order status (#24)
   - Product inquiries (#25-#27)
   - Escalation flow (#28)
   - Support ticket creation (#64)

2. **High** - Important for customer satisfaction:
   - Returns/refunds (#29-#31)
   - Prospect product discovery (#54-#57)
   - Email capture (#58)

3. **Medium** - Enhances experience:
   - Subscriptions (#32)
   - Loyalty program (#33)
   - Shipping questions (#34)

4. **Low** - Nice to have:
   - Gift orders (#35)
   - Store hours (#36)
   - Customization requests (#37)

**Your Priority** (rank top 15 stories by importance):
1. Issue # _______
2. Issue # _______
3. Issue # _______
(Continue...)

### 5. Development Approach

**Decision Needed**: How do you want to proceed?

**Option A - Sequential** (Safer, slower)
- Implement one agent at a time fully
- Test thoroughly before moving to next
- Timeline: 8-10 weeks

**Option B - Parallel** (Faster, requires coordination)
- Implement all agents concurrently
- Integrate and test together
- Timeline: 6-8 weeks

**Option C - Story-Driven** (Recommended)
- Pick top priority stories
- Implement just enough agent logic for those stories
- Add complexity incrementally
- Timeline: 6-8 weeks

**Your Choice**: _________________

---

## üìÖ Suggested Timeline

### Week 1-2: Foundation
- Implement Intent Classification Agent core logic
- Set up conversation flow management
- Create integration test framework
- Complete top 5 priority stories

### Week 3-4: Retrieval & Response
- Implement Knowledge Retrieval Agent
- Implement Response Generation Agent
- Complete customer order and product stories (15-20 stories)
- Achieve 50% Phase 2 completion

### Week 5-6: Escalation & Workflows
- Implement Escalation Agent
- Implement Analytics Agent
- Complete support/service/sales stories
- Integrate all agents via A2A protocol

### Week 7-8: Testing & Refinement
- Integration testing
- Multi-agent conversation flow testing
- Bug fixes and optimizations
- Increase test coverage to >70%
- Prepare for Phase 3

---

## ‚úÖ Phase 2 Entry Criteria Checklist

Before starting Phase 2, verify:

**Phase 1 Completion**:
- [x] All 5 agent skeletons exist
- [x] All 4 mock APIs operational
- [x] Docker Compose working
- [x] Shared utilities complete
- [x] Test framework established (46% coverage baseline)

**Ready to Code**:
- [ ] Business logic decisions documented (see Section 1)
- [ ] Test scenarios defined (see Section 2)
- [ ] Knowledge base content available (see Section 3)
- [ ] Story priorities set (see Section 4)
- [ ] Development approach chosen (see Section 5)

**Environment Validated**:
- [ ] Docker Compose up and healthy
- [ ] All mock APIs responding (curl localhost:8001-8004)
- [ ] Pytest runs successfully
- [ ] AGNTCY SDK factory initializes

---

## üéì Resources & Documentation

### Key Documents to Review
1. **AGNTCY-REVIEW.md** - SDK integration patterns
2. **PROJECT-README.txt** - Overall project requirements
3. **CLAUDE.md** - Development guidelines and constraints
4. **user-stories-phased.md** - Phase 2 story details (#24-#73)

### AGNTCY SDK Documentation
- Factory pattern usage
- A2A protocol examples
- Message routing
- Session management
- Error handling

### Example Code Patterns
Located in existing agent implementations from Phase 1:
- `agents/intent_classification/agent.py` - Basic structure
- `shared/factory.py` - Singleton pattern
- `shared/models.py` - Message formats

---

## üìû Next Steps

### Immediate Actions Required from You:

1. **Complete Input Sections** (1-2 hours)
   - Fill in business logic decisions
   - Provide test scenarios
   - Share knowledge base content
   - Set story priorities
   - Choose development approach

2. **Review Phase 2 Stories** (30 minutes)
   - Review issues #24-#73 in GitHub
   - Confirm they match your business needs
   - Flag any that need modification

3. **Validate Phase 1** (30 minutes)
   - Run `docker-compose up`
   - Verify all services healthy
   - Run `pytest tests/`
   - Confirm 63 tests passing

### Then I Can Begin:

Once you provide the above inputs, I can:
1. Implement agent business logic based on your decisions
2. Create realistic test data from your scenarios
3. Build knowledge base from your content
4. Prioritize work based on your rankings
5. Start coding Phase 2 immediately

---

## üí° Questions Before We Start?

Do you have any questions about:
- [ ] The scope of Phase 2?
- [ ] The technical approach?
- [ ] The timeline estimates?
- [ ] The decisions needed from you?
- [ ] How to provide the required inputs?

---

**Document Created**: 2026-01-22
**Phase 2 Estimated Start**: Upon receiving your input
**Phase 2 Target Completion**: 2026-04-30 (8 weeks from start)
**Budget**: $0/month (local development only)

---

## üöÄ Ready to Build World-Class AI Agents!

Once you provide the input sections above, we'll transform the infrastructure from Phase 1 into an intelligent, conversation-capable multi-agent system that delights your customers!
